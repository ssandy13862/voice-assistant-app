package com.voiceassistant.app.data.repository

import android.content.Context
import android.os.Build
import android.speech.tts.TextToSpeech
import android.speech.tts.UtteranceProgressListener
import android.util.Log
import com.voiceassistant.app.data.api.ChatCompletionRequest
import com.voiceassistant.app.data.api.ChatMessage
import com.voiceassistant.app.data.api.OpenAiApi
import com.voiceassistant.app.data.api.WhisperApi
import com.voiceassistant.app.domain.repository.SpeechRepository
import dagger.hilt.android.qualifiers.ApplicationContext
import kotlinx.coroutines.suspendCancellableCoroutine
import okhttp3.MediaType.Companion.toMediaTypeOrNull
import okhttp3.MultipartBody
import okhttp3.RequestBody.Companion.asRequestBody
import okhttp3.RequestBody.Companion.toRequestBody
import java.io.File
import java.util.*
import javax.inject.Inject
import javax.inject.Singleton
import kotlin.coroutines.resume

/**
 * èªéŸ³è™•ç†å€‰åº«å¯¦ä½œ
 */
@Singleton
class SpeechRepositoryImpl @Inject constructor(
    @ApplicationContext private val context: Context,
    private val openAiApi: OpenAiApi,
    private val whisperApi: WhisperApi,
    private val whisperNativeRepository: WhisperNativeRepository
) : SpeechRepository {

    private var textToSpeech: TextToSpeech? = null
    private var isTtsInitialized = false
    private var isSpeaking = false
    private var useLocalWhisper = false // é è¨­ä½¿ç”¨é ç«¯ Whisperï¼Œéœ€è¦æª¢æŸ¥æœ¬åœ°æ¨¡å‹å¾Œå†æ±ºå®š
    private var isWhisperInitialized = false
    
    // OpenAI APIé…ç½®
    private val openAiApiKey = com.voiceassistant.app.BuildConfig.OPENAI_API_KEY
    private val isApiKeyValid = openAiApiKey != "your_openai_api_key_here" && openAiApiKey.isNotBlank()
    private val systemPrompt = """
        ä½ æ˜¯ä¸€å€‹æ™ºæ…§èªéŸ³åŠ©ç†ï¼Œéœ€è¦ï¼š
        1. ç”¨è‡ªç„¶ã€å‹å¥½çš„èªèª¿å›æ‡‰
        2. å›ç­”è¦ç°¡æ½”æ˜ç­ï¼Œé©åˆèªéŸ³äº¤æµ
        3. å¯ä»¥é€²è¡Œæ—¥å¸¸å°è©±ã€å›ç­”å•é¡Œã€æä¾›å¹«åŠ©
        4. ä¿æŒå°è©±çš„é€£è²«æ€§å’Œä¸Šä¸‹æ–‡
        5. ç”¨ä¸­æ–‡å›ç­”ï¼Œé™¤éä½¿ç”¨è€…æ˜ç¢ºè¦æ±‚ä½¿ç”¨å…¶ä»–èªè¨€
    """.trimIndent()

    init {
        initializeTTS()
        initializeWhisper()
    }
    
    /**
     * åˆå§‹åŒ– Whisperï¼ˆæª¢æŸ¥æœ¬åœ°æ¨¡å‹æ˜¯å¦å¯ç”¨ï¼‰
     */
    private fun initializeWhisper() {
        try {
            // é¦–å…ˆå˜—è©¦å®‰è£æ¨¡å‹
            android.util.Log.d("SpeechRepository", "æª¢æŸ¥ä¸¦å®‰è£ Whisper æ¨¡å‹...")
            val modelInstalled = whisperNativeRepository.installModel()
            
            if (modelInstalled && whisperNativeRepository.isModelAvailable()) {
                android.util.Log.i("SpeechRepository", "æœ¬åœ° Whisper æ¨¡å‹å¯ç”¨ï¼Œå˜—è©¦åˆå§‹åŒ–...")
                val modelPath = whisperNativeRepository.getModelPath()
                isWhisperInitialized = whisperNativeRepository.initializeWhisper(modelPath)
                
                if (isWhisperInitialized) {
                    useLocalWhisper = true
                    android.util.Log.i("SpeechRepository", "æœ¬åœ° Whisper åˆå§‹åŒ–æˆåŠŸï¼Œä½¿ç”¨æœ¬åœ°è­˜åˆ¥")
                } else {
                    android.util.Log.w("SpeechRepository", "æœ¬åœ° Whisper åˆå§‹åŒ–å¤±æ•—ï¼Œä½¿ç”¨é ç«¯ API")
                }
            } else {
                android.util.Log.i("SpeechRepository", "æœ¬åœ° Whisper æ¨¡å‹ä¸å¯ç”¨ï¼Œä½¿ç”¨é ç«¯ API")
                android.util.Log.i("SpeechRepository", "æç¤ºï¼šè«‹åƒè€ƒ assets/download_whisper_model.md æ‰‹å‹•å®‰è£æ¨¡å‹")
            }
        } catch (e: Exception) {
            android.util.Log.e("SpeechRepository", "Whisper åˆå§‹åŒ–ç•°å¸¸", e)
            useLocalWhisper = false
        }
    }

    private fun initializeTTS() {
        textToSpeech = TextToSpeech(context) { status ->
            if (status == TextToSpeech.SUCCESS) {
                textToSpeech?.language = Locale.CHINESE
                isTtsInitialized = true
            }
        }
    }

    override suspend fun speechToText(audioFile: File): Result<String> {

        // åˆå§‹åŒ– Whisper
        Log.d("SpeechRepository", "åˆå§‹åŒ– Whisper...")
        initializeWhisper()

        android.util.Log.i("SpeechRepository", "é–‹å§‹èªéŸ³è­˜åˆ¥ï¼Œä½¿ç”¨ ${if (useLocalWhisper) "æœ¬åœ° Whisper" else "é ç«¯ API"}")
        android.util.Log.d("SpeechRepository", "éŸ³é »æ–‡ä»¶: ${audioFile.absolutePath}, å¤§å°: ${audioFile.length()} bytes")
        
        return if (useLocalWhisper && isWhisperInitialized) {
            speechToTextLocal(audioFile)
        } else {
            if (useLocalWhisper && !isWhisperInitialized) {
                android.util.Log.w("SpeechRepository", "æœ¬åœ° Whisper æœªåˆå§‹åŒ–ï¼Œåˆ‡æ›åˆ°é ç«¯ API")
            }
            speechToTextRemote(audioFile)
        }
    }
    
    /**
     * ä½¿ç”¨æœ¬åœ° Whisper é€²è¡ŒèªéŸ³è­˜åˆ¥
     */
    private suspend fun speechToTextLocal(audioFile: File): Result<String> {
        return try {
            // è®€å–éŸ³é »æ–‡ä»¶ä¸¦è½‰æ›ç‚º FloatArray
            val audioData = readAudioFile(audioFile)
            
            if (audioData.isEmpty()) {
                return Result.failure(Exception("éŸ³é »æ–‡ä»¶ç‚ºç©ºæˆ–æ ¼å¼ä¸æ”¯æŒ"))
            }
            
            android.util.Log.d("SpeechRepository", "ä½¿ç”¨æœ¬åœ° Whisper è­˜åˆ¥ï¼Œæ¨£æœ¬æ•¸: ${audioData.size}")
            
            // èª¿ç”¨æœ¬åœ° Whisper
            val transcription = whisperNativeRepository.transcribeAudio(audioData)
            
            if (transcription.isNotBlank()) {
                android.util.Log.d("SpeechRepository", "æœ¬åœ°è­˜åˆ¥çµæœ: $transcription")
                Result.success(transcription)
            } else {
                Result.failure(Exception("æœ¬åœ° Whisper è­˜åˆ¥å¤±æ•—æˆ–è¿”å›ç©ºçµæœ"))
            }
        } catch (e: Exception) {
            android.util.Log.e("SpeechRepository", "æœ¬åœ° Whisper ç•°å¸¸", e)
            Result.failure(e)
        }
    }
    
    /**
     * ä½¿ç”¨é ç¨‹ Whisper API é€²è¡ŒèªéŸ³è­˜åˆ¥
     */
    private suspend fun speechToTextRemote(audioFile: File): Result<String> {
        return try {
            if (!isApiKeyValid) {
                android.util.Log.e("SpeechRepository", "OpenAI API Key ç„¡æ•ˆæˆ–æœªè¨­ç½®")
                return Result.failure(Exception("éœ€è¦è¨­ç½®æœ‰æ•ˆçš„ OpenAI API Key"))
            }
            
            if (!audioFile.exists() || audioFile.length() == 0L) {
                android.util.Log.e("SpeechRepository", "éŸ³é »æ–‡ä»¶ä¸å­˜åœ¨æˆ–ç‚ºç©º")
                return Result.failure(Exception("éŸ³é »æ–‡ä»¶ç„¡æ•ˆ"))
            }
            
            android.util.Log.d("SpeechRepository", "ä½¿ç”¨é ç«¯ Whisper APIï¼Œæ–‡ä»¶å¤§å°: ${audioFile.length()} bytes")
            
            // å‰µå»ºéŸ³é »æ–‡ä»¶çš„ RequestBody
            val requestFile = audioFile.asRequestBody("audio/wav".toMediaTypeOrNull())
            val filePart = MultipartBody.Part.createFormData("file", audioFile.name, requestFile)
            
            // å‰µå»ºæ¨¡å‹å’Œèªè¨€åƒæ•¸
            val modelPart = "whisper-1".toRequestBody("text/plain".toMediaTypeOrNull())
            val languagePart = "zh".toRequestBody("text/plain".toMediaTypeOrNull())
            
            // èª¿ç”¨ Whisper API
            val response = whisperApi.transcribeAudio(
                authorization = "Bearer $openAiApiKey",
                file = filePart,
                model = modelPart,
                language = languagePart
            )
            
            if (response.isSuccessful) {
                val transcription = response.body()?.text ?: ""
                Result.success(transcription)
            } else {
                val errorBody = response.errorBody()?.string() ?: "Unknown error"
                Result.failure(Exception("Whisper API error: ${response.code()} - $errorBody"))
            }
        } catch (e: Exception) {
            Result.failure(e)
        }
    }
    
    /**
     * è®€å–éŸ³é »æ–‡ä»¶ä¸¦è½‰æ›ç‚º FloatArray
     */
    private fun readAudioFile(audioFile: File): FloatArray {
        return try {
            if (!audioFile.exists()) {
                android.util.Log.e("SpeechRepository", "éŸ³é »æ–‡ä»¶ä¸å­˜åœ¨: ${audioFile.absolutePath}")
                return floatArrayOf()
            }
            
            // ç°¡åŒ–çš„éŸ³é »è®€å–ï¼ˆå‡è¨­ç‚º 16-bit PCMï¼‰
            val bytes = audioFile.readBytes()
            val floats = FloatArray(bytes.size / 2)
            
            for (i in floats.indices) {
                val index = i * 2
                if (index + 1 < bytes.size) {
                    // Little-endian 16-bit PCM to float
                    val sample = ((bytes[index + 1].toInt() shl 8) or (bytes[index].toInt() and 0xFF)).toShort()
                    floats[i] = sample / 32768.0f
                }
            }
            
            android.util.Log.d("SpeechRepository", "éŸ³é »æ–‡ä»¶è®€å–å®Œæˆ: ${floats.size} æ¨£æœ¬")
            floats
        } catch (e: Exception) {
            android.util.Log.e("SpeechRepository", "è®€å–éŸ³é »æ–‡ä»¶å¤±æ•—", e)
            floatArrayOf()
        }
    }

    override suspend fun processAiConversation(
        userInput: String, 
        conversationHistory: List<String>
    ): Result<String> {
        return try {
            // æ·»åŠ ç¶²è·¯é€£ç·šè¨ºæ–·
            android.util.Log.d("SpeechRepository", "é–‹å§‹ OpenAI API èª¿ç”¨...")
            
            // æš«æ™‚è·³éçœŸå¯¦ APIï¼Œç›´æ¥ä½¿ç”¨ Mockï¼ˆç”¨æ–¼æ¸¬è©¦ï¼‰
            // TODO: æ¢å¾©çœŸå¯¦ API èª¿ç”¨
//            android.util.Log.w("SpeechRepository", "æš«æ™‚ä½¿ç”¨ Mock æ¨¡å¼ä»¥é¿å…ç¶²è·¯å•é¡Œ")
//            return Result.success(getMockResponse(userInput))
            
            // é¦–å…ˆå˜—è©¦èª¿ç”¨çœŸå¯¦çš„OpenAI API
            val messages = mutableListOf<ChatMessage>()
            
            // æ–°å¢ç³»çµ±æç¤º
            messages.add(ChatMessage("system", systemPrompt))
            
            // æ–°å¢å°è©±æ­·å²
            conversationHistory.forEachIndexed { index, message ->
                val role = if (index % 2 == 0) "user" else "assistant"
                messages.add(ChatMessage(role, message))
            }
            
            // æ–°å¢ç›®å‰ä½¿ç”¨è€…è¼¸å…¥
            messages.add(ChatMessage("user", userInput))
            
            val request = ChatCompletionRequest(
                model = "gpt-3.5-turbo",
                messages = messages,
                maxTokens = 150,
                temperature = 0.7f
            )
            
            val response = openAiApi.createChatCompletion(
                authorization = "Bearer $openAiApiKey",
                request = request
            )
            
            if (response.isSuccessful) {
                val aiResponse = response.body()?.choices?.firstOrNull()?.message?.content ?: ""
                Result.success(aiResponse)
            } else {
                // APIèª¿ç”¨å¤±æ•—ï¼Œä½¿ç”¨Mockå›æ‡‰ä½œç‚ºå‚™ä»½
                android.util.Log.w("SpeechRepository", "OpenAI APIå¤±æ•—ï¼Œä½¿ç”¨Mockå›æ‡‰: ${response.code()}")
                Result.success(getMockResponse(userInput))
            }
        } catch (e: Exception) {
            // ç¶²è·¯æˆ–å…¶ä»–ç•°å¸¸ï¼Œä½¿ç”¨Mockå›æ‡‰ä½œç‚ºå‚™ä»½
            android.util.Log.w("SpeechRepository", "APIèª¿ç”¨ç•°å¸¸ï¼Œä½¿ç”¨Mockå›æ‡‰: ${e.message}")
            Result.success(getMockResponse(userInput))
        }
    }

    /**
     * ç²å–Mockå›æ‡‰ï¼ˆç”¨æ–¼æ¸¬è©¦å’ŒAPIå¤±æ•—æ™‚çš„å‚™ä»½ï¼‰
     */
    private fun getMockResponse(userInput: String): String {
        val mockResponses = mapOf(
            "ä½ å¥½ï¼Œä»Šå¤©å¤©æ°£æ€éº¼æ¨£ï¼Ÿ" to "ä½ å¥½ï¼æˆ‘æ˜¯æ™ºæ…§èªéŸ³åŠ©ç†ï¼Œå¾ˆé«˜èˆˆç‚ºæ‚¨æœå‹™ã€‚é—œæ–¼å¤©æ°£ï¼Œæˆ‘å»ºè­°æ‚¨æŸ¥çœ‹å¤©æ°£æ‡‰ç”¨ç²å–æº–ç¢ºè³‡è¨Šã€‚â˜€ï¸",
            "è«‹å‘Šè¨´æˆ‘ä¸€å€‹ç¬‘è©±" to "ç‚ºä»€éº¼ç¨‹å¼è¨­è¨ˆå¸«å–œæ­¡æš—å…‰ï¼Ÿå› ç‚º Light attracts bugsï¼å“ˆå“ˆï¼ğŸ˜„ é‚„éœ€è¦å…¶ä»–ç¬‘è©±å—ï¼Ÿ",
            "ç¾åœ¨å¹¾é»äº†ï¼Ÿ" to "æŠ±æ­‰ï¼Œæˆ‘ç„¡æ³•ç²å–ç•¶å‰æ™‚é–“ï¼Œè«‹æŸ¥çœ‹æ‚¨çš„è¨­å‚™æ™‚é˜ã€‚â° æœ‰ä»€éº¼å…¶ä»–æˆ‘å¯ä»¥å¹«åŠ©æ‚¨çš„å—ï¼Ÿ",
            "ä½ å¯ä»¥åšä»€éº¼ï¼Ÿ" to "æˆ‘å¯ä»¥é€²è¡Œå°è©±ã€å›ç­”å•é¡Œã€æä¾›å¹«åŠ©å’Œå»ºè­°ã€‚æˆ‘æ˜¯æ‚¨çš„æ™ºæ…§èªéŸ³åŠ©ç†ï¼ğŸ¤– è©¦è©¦å•æˆ‘ä»»ä½•å•é¡Œå§ï¼",
            "è¬è¬ä½ çš„å¹«åŠ©" to "ä¸å®¢æ°£ï¼å¾ˆé«˜èˆˆèƒ½å¤ å¹«åŠ©æ‚¨ã€‚ğŸ˜Š æœ‰ä»»ä½•å•é¡Œéƒ½å¯ä»¥éš¨æ™‚å•æˆ‘ï¼",
            "æ’­æ”¾éŸ³æ¨‚" to "æŠ±æ­‰ï¼Œæˆ‘ç„¡æ³•ç›´æ¥æ’­æ”¾éŸ³æ¨‚ï¼Œä½†æˆ‘å»ºè­°æ‚¨ä½¿ç”¨éŸ³æ¨‚æ‡‰ç”¨ç¨‹å¼å¦‚ Spotify æˆ– Apple Musicã€‚ğŸµ",
            "è¨­å®šé¬§é˜æ˜å¤©æ—©ä¸Š7é»" to "å¾ˆæŠ±æ­‰ï¼Œæˆ‘ç„¡æ³•ç›´æ¥è¨­å®šé¬§é˜ã€‚è«‹ä½¿ç”¨æ‚¨æ‰‹æ©Ÿçš„æ™‚é˜æ‡‰ç”¨ç¨‹å¼ä¾†è¨­å®šæ˜å¤©æ—©ä¸Š7é»çš„é¬§é˜ã€‚â°",
            "ä»Šå¤©çš„æ–°èæœ‰ä»€éº¼ï¼Ÿ" to "æˆ‘ç„¡æ³•ç²å–å¯¦æ™‚æ–°èï¼Œå»ºè­°æ‚¨æŸ¥çœ‹æ–°èæ‡‰ç”¨ç¨‹å¼æˆ–ç¶²ç«™ç²å–æœ€æ–°è³‡è¨Šã€‚ğŸ“°",
            "å¹«æˆ‘æŸ¥è©¢å¤©æ°£é å ±" to "æˆ‘ç„¡æ³•ç›´æ¥æŸ¥è©¢å¤©æ°£é å ±ï¼Œè«‹ä½¿ç”¨å¤©æ°£æ‡‰ç”¨ç¨‹å¼æˆ–è©¢å•èªéŸ³åŠ©ç†å¦‚ Siri ç²å–æº–ç¢ºçš„å¤©æ°£è³‡è¨Šã€‚ğŸŒ¤ï¸",
            "æˆ‘æƒ³å­¸ç¿’æ–°çš„çŸ¥è­˜" to "å¤ªæ£’äº†ï¼å­¸ç¿’æ˜¯å¾ˆå¥½çš„ç¿’æ…£ã€‚æ‚¨æƒ³å­¸ç¿’ä»€éº¼ä¸»é¡Œå‘¢ï¼Ÿæˆ‘å¯ä»¥çµ¦æ‚¨ä¸€äº›å»ºè­°å’Œå­¸ç¿’æ–¹å‘ã€‚ğŸ“š"
        )
        
        // å¦‚æœæœ‰å®Œå…¨åŒ¹é…çš„å›æ‡‰ï¼Œä½¿ç”¨å®ƒ
        mockResponses[userInput]?.let { return it }
        
        // å¦‚æœæ²’æœ‰å®Œå…¨åŒ¹é…ï¼ŒåŸºæ–¼é—œéµè©æä¾›å›æ‡‰
        return when {
            userInput.contains("ä½ å¥½") || userInput.contains("å—¨") -> 
                "ä½ å¥½ï¼å¾ˆé«˜èˆˆå’Œæ‚¨èŠå¤©ï¼ğŸ˜Š æœ‰ä»€éº¼æˆ‘å¯ä»¥å¹«åŠ©æ‚¨çš„å—ï¼Ÿ"
            userInput.contains("è¬è¬") || userInput.contains("æ„Ÿè¬") -> 
                "ä¸å®¢æ°£ï¼å¾ˆé«˜èˆˆèƒ½å¹«åŠ©æ‚¨ï¼ğŸ˜Š"
            userInput.contains("å†è¦‹") || userInput.contains("æ‹œæ‹œ") -> 
                "å†è¦‹ï¼æœŸå¾…ä¸‹æ¬¡å’Œæ‚¨èŠå¤©ï¼ğŸ‘‹"
            userInput.contains("æ™‚é–“") || userInput.contains("å¹¾é»") -> 
                "è«‹æŸ¥çœ‹æ‚¨çš„è¨­å‚™æ™‚é˜ç²å–ç•¶å‰æ™‚é–“ã€‚â°"
            userInput.contains("å¤©æ°£") -> 
                "è«‹ä½¿ç”¨å¤©æ°£æ‡‰ç”¨ç¨‹å¼ç²å–æº–ç¢ºçš„å¤©æ°£è³‡è¨Šã€‚ğŸŒ¤ï¸"
            userInput.contains("éŸ³æ¨‚") -> 
                "å»ºè­°æ‚¨ä½¿ç”¨å°ˆé–€çš„éŸ³æ¨‚æ‡‰ç”¨ç¨‹å¼ä¾†æ’­æ”¾éŸ³æ¨‚ã€‚ğŸµ"
            userInput.contains("ç¬‘è©±") -> 
                "é€™è£¡æœ‰ä¸€å€‹ç¨‹å¼è¨­è¨ˆå¸«ç¬‘è©±ï¼šç‚ºä»€éº¼ Java å·¥ç¨‹å¸«è¦æˆ´çœ¼é¡ï¼Ÿå› ç‚ºä»–å€‘çœ‹ä¸è¦‹ Cï¼ğŸ˜„"
            else -> 
                "æ„Ÿè¬æ‚¨çš„æå•ï¼šã€Œ$userInputã€ã€‚æˆ‘æ­£åœ¨ä¸æ–·å­¸ç¿’ä¸­ï¼Œå¸Œæœ›æœªä¾†èƒ½æ›´å¥½åœ°å›ç­”æ‚¨çš„å•é¡Œï¼ğŸ¤–"
        }
    }

    override suspend fun textToSpeech(text: String): Result<Unit> {
        return suspendCancellableCoroutine { continuation ->
            if (!isTtsInitialized || textToSpeech == null) {
                continuation.resume(Result.failure(Exception("TTS not initialized")))
                return@suspendCancellableCoroutine
            }
            
            val utteranceId = UUID.randomUUID().toString()
            
            textToSpeech?.setOnUtteranceProgressListener(object : UtteranceProgressListener() {
                override fun onStart(utteranceId: String?) {
                    isSpeaking = true
                }
                
                override fun onDone(utteranceId: String?) {
                    isSpeaking = false
                    if (continuation.isActive) {
                        continuation.resume(Result.success(Unit))
                    }
                }
                
                override fun onError(utteranceId: String?) {
                    isSpeaking = false
                    if (continuation.isActive) {
                        continuation.resume(Result.failure(Exception("TTS error")))
                    }
                }
            })
            
            val result = textToSpeech?.speak(text, TextToSpeech.QUEUE_FLUSH, null, utteranceId)
            
            if (result != TextToSpeech.SUCCESS) {
                continuation.resume(Result.failure(Exception("TTS speak failed")))
            }
            
            continuation.invokeOnCancellation {
                stopTTS()
            }
        }
    }

    override fun stopTTS() {
        textToSpeech?.stop()
        isSpeaking = false
    }

    override fun isTTSSpeaking(): Boolean {
        return isSpeaking
    }

    override fun setTTSLanguage(language: String) {
        val locale = when (language) {
            "zh" -> Locale.CHINESE
            "en" -> Locale.ENGLISH
            else -> Locale.CHINESE
        }
        textToSpeech?.language = locale
    }

    override fun setTTSSpeed(speed: Float) {
        textToSpeech?.setSpeechRate(speed)
    }
}
